"""
app.py - Interface Graphique Web avec Streamlit (PARTIE 2/2 - INTERFACE UTILISATEUR)

Cette partie contient l'interface utilisateur compl√®te avec:
- Sidebar pour les contr√¥les (pr√©traitement, configuration IA)
- Zone d'upload d'images
- Visualisation c√¥te √† c√¥te (avant/apr√®s)
- Tableaux de r√©sultats (une image / batch)
- Graphiques de statistiques
"""

# [IMPORTS ET FONCTIONS DE LA PARTIE 1 - Voir app_part1.py]

# ========== 5. INTERFACE PRINCIPALE ==========

# ========== EN-T√äTE DE L'APPLICATION ==========
st.title("D√©tecteur d'avions")  # Titre principal de la page
st.markdown("**Architecture :** PyTorch (Faster R-CNN) ")  # Sous-titre avec l'architecture

# ========== SIDEBAR - SECTION PR√âTRAITEMENT IMAGE ==========
st.sidebar.header("üéõÔ∏è Options de pr√©-traitement image")

# Slider pour ajuster la luminosit√©
# Plage: -50 √† +50, valeur par d√©faut: 0 (pas de changement)
bri = st.sidebar.slider("Luminosit√©", -50, 50, 0)

# Slider pour ajuster le contraste
# Plage: 0.5 (faible contraste) √† 2.0 (fort contraste), valeur par d√©faut: 1.0
con = st.sidebar.slider("Contraste", 0.5, 2.0, 1.0)

# Slider pour correction gamma
# Plage: 0.5 (√©claircit) √† 2.5 (assombrit), valeur par d√©faut: 1.0
gam = st.sidebar.slider("Gamma", 0.5, 2.5, 1.0)

# Slider pour am√©lioration de la nettet√©
# Plage: 0 (pas d'am√©lioration) √† 10 (tr√®s net), valeur par d√©faut: 0
sha = st.sidebar.slider("Nettet√© (Edges)", 0, 10, 0)

st.sidebar.markdown("---")  # Ligne de s√©paration horizontale

# ========== SIDEBAR - SECTION CONFIGURATION IA ==========
st.sidebar.header("üß† Configuration")

# Champ texte pour sp√©cifier le chemin du mod√®le
# Valeur par d√©faut: models/faster_rcnn_avions_V2.pth
default_path = os.path.join("models", "faster_rcnn_avions_V2.pth")
model_path = st.sidebar.text_input("Chemin Mod√®le (.pth)", default_path)

# Slider pour le seuil de d√©tection (confidence threshold)
# Plage: 0.0 (accepte tout) √† 1.0 (tr√®s strict), valeur par d√©faut: 0.50
conf_thresh = st.sidebar.slider("Seuil D√©tection (Pr√©cision)", 0.0, 1.0, 0.50)

# Slider pour le seuil NMS (Non-Maximum Suppression)
# Plage: 0.0 √† 1.0, valeur par d√©faut: 0.3
# Plus bas = √©limine plus de doublons, plus haut = garde plus de bo√Ætes
nms_thresh = st.sidebar.slider("Seuil Doublons (NMS)", 0.0, 1.0, 0.3)

# ========== CHARGEMENT DU MOD√àLE (AVEC CACHE) ==========
# load_system() est appel√©e avec le chemin du mod√®le
# Gr√¢ce au d√©corateur @st.cache_resource, le mod√®le n'est charg√© qu'une seule fois
model, status = load_system(model_path)

# Affichage du statut dans la sidebar
if status:
    # Si le mod√®le est charg√© avec succ√®s, affiche un message vert
    st.sidebar.success("‚úÖ SYST√àME EN LIGNE")
else:
    # Si le chargement a √©chou√©, affiche un message d'erreur rouge
    st.sidebar.error(f"‚ö†Ô∏è HORS LIGNE : Impossible de trouver '{model_path}'")

# ========== ZONE D'UPLOAD D'IMAGES ==========
# st.file_uploader() cr√©e un bouton pour uploader des fichiers
# type: limite aux formats image
# accept_multiple_files=True: permet de s√©lectionner plusieurs images en une fois
uploaded_files = st.file_uploader(
    "IMPORTER UNE IMAGE SATELLITE", 
    type=['jpg', 'png', 'jpeg'], 
    accept_multiple_files=True
)

# ========== TRAITEMENT DES IMAGES UPLOAD√âES ==========
if uploaded_files:
    # Si l'utilisateur a upload√© au moins une image
    
    # ========== GESTION MULTI-FICHIERS ==========
    if len(uploaded_files) > 1:
        # Si plusieurs images, affiche le nombre total
        st.info(f"üóÇ {len(uploaded_files)} fichiers charg√©s.")
        
        # Cr√©ation d'un dictionnaire {nom_fichier: objet_fichier}
        file_map = {f.name: f for f in uploaded_files}
        
        # Dropdown pour s√©lectionner quelle image visualiser
        selected_name = st.selectbox("S√©lectionner une image √† visualiser :", list(file_map.keys()))
        
        # R√©cup√©ration de l'objet fichier s√©lectionn√©
        selected_file = file_map[selected_name]
    else:
        # Si une seule image, la s√©lectionne automatiquement
        selected_file = uploaded_files[0]
        selected_name = selected_file.name

    # ========== 1. CHARGEMENT ET PR√âTRAITEMENT DE L'IMAGE ==========
    # Lecture du fichier upload√© en bytes
    file_bytes = np.asarray(bytearray(selected_file.read()), dtype=np.uint8)
    
    # R√©initialisation du curseur du fichier (n√©cessaire pour relire plus tard)
    selected_file.seek(0)
    
    # D√©codage des bytes en image OpenCV (array NumPy BGR)
    img_raw = cv2.imdecode(file_bytes, 1)
    
    # Application des ajustements d'image (luminosit√©, contraste, gamma, nettet√©)
    img_processed = process_signal(img_raw, bri, con, gam, sha)
    
    # ========== 2. INF√âRENCE (D√âTECTION) ==========
    detections = []  # Liste qui stockera les d√©tections
    output_img = img_processed.copy()  # Copie de l'image pour dessiner dessus
    
    # D√©marrage du chronom√®tre pour mesurer le temps de traitement
    t_start = time.perf_counter()
    
    # Si le mod√®le est charg√©, effectue l'inf√©rence
    if status:
        # Appel de la fonction d'inf√©rence
        detections = run_inference_pytorch(model, img_processed, conf_thresh, nms_thresh)
        
        # ========== DESSIN DES BO√éTES SUR L'IMAGE ==========
        for res in detections:
            # Extraction de la bo√Æte et conversion en int
            box = res['box']
            x1, y1, x2, y2 = map(int, box)
            
            # Couleur verte (format BGR pour OpenCV)
            color = (0, 255, 0)
            
            # Dessin du rectangle sur l'image
            cv2.rectangle(output_img, (x1, y1), (x2, y2), color, 2)
            
            # Construction du label texte
            label_txt = f"{res['label']} P:{res['score']:.2f}"
            
            # Dessin du texte au-dessus de la bo√Æte
            cv2.putText(output_img, label_txt, (x1, y1-5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
    
    # Calcul du temps de traitement en millisecondes
    latency_ms = (time.perf_counter() - t_start) * 1000

    # ========== 3. AFFICHAGE C√îTE √Ä C√îTE ==========
    # st.columns(2) cr√©e 2 colonnes de largeur √©gale
    c1, c2 = st.columns(2)
    
    # Colonne de gauche : image originale
    with c1:
        st.caption("Entr√©e")  # L√©gende
        # Conversion BGR (OpenCV) ‚Üí RGB (Streamlit)
        # use_container_width=True adapte la largeur √† la colonne
        st.image(cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB), use_container_width=True)
    
    # Colonne de droite : image annot√©e
    with c2:
        st.caption(f"Sortie")  # L√©gende
        # Affichage de l'image avec les d√©tections dessin√©es
        st.image(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB), use_container_width=True)
        # M√©trique affichant le temps de traitement
        st.metric("Temps de traitement", f"{latency_ms:.1f} ms")

    # ========== S√âPARATEUR ==========
    st.markdown("---")  # Ligne horizontale
    st.subheader("üìã R√©sultats")  # Sous-titre

    # ========== ONGLETS DE R√âSULTATS ==========
    # st.tabs() cr√©e des onglets cliquables
    tab_single, tab_batch = st.tabs(["üîé Pour une image", "üåê Pour plusieurs images"])

    # ========== ONGLET 1 : R√âSULTATS POUR UNE IMAGE ==========
    with tab_single:
        if detections:
            # Si des avions ont √©t√© d√©tect√©s
            
            # Construction d'un DataFrame Pandas pour affichage en tableau
            data_list = []
            for d in detections:
                # Extraction et conversion des coordonn√©es en int
                x1, y1, x2, y2 = map(int, d['box'])
                
                # Ajout d'une ligne au tableau
                data_list.append({
                    "Image": selected_name,
                    "Classe": d['label'],
                    "Pr√©cision": f"{d['score']:.2%}",  # Format en pourcentage
                    "Coordonn√©es": f"[{x1}, {y1}, {x2}, {y2}]"
                })
            
            # Conversion de la liste en DataFrame Pandas
            df_single = pd.DataFrame(data_list)
            
            # Affichage en 2 colonnes : tableau + m√©triques
            c_table, c_metric = st.columns([3, 1])  # Ratio 3:1
            
            with c_table:
                # Affichage du tableau des d√©tections
                st.dataframe(df_single, use_container_width=True)
            
            with c_metric:
                # M√©triques r√©capitulatives
                st.metric("Avions D√©tect√©s", len(detections))
                # Calcul de la pr√©cision moyenne
                avg_score = pd.Series([d['score'] for d in detections]).mean()
                st.metric("Pr√©cision Moyenne", f"{avg_score:.1%}")
        else:
            # Si aucune d√©tection
            st.info("Aucun avion d√©tect√© sur cette image.")

    # ========== ONGLET 2 : TRAITEMENT BATCH (PLUSIEURS IMAGES) ==========
    with tab_batch:
        if len(uploaded_files) > 1:
            # Si plusieurs images ont √©t√© upload√©es
            st.write("Analyse de l'ensemble des fichiers import√©s.")
            
            # Bouton pour lancer le traitement batch
            if st.button(f"LANCER LE TRAITEMENT SUR {len(uploaded_files)} FICHIERS"):
                
                if status:
                    # Si le mod√®le est charg√©
                    
                    all_detections = []  # Liste qui stockera toutes les d√©tections
                    
                    # Cr√©ation d'une barre de progression
                    progress_bar = st.progress(0)
                    
                    # ========== BOUCLE SUR TOUTES LES IMAGES ==========
                    for i, file in enumerate(uploaded_files):
                        # R√©initialisation du curseur
                        file.seek(0)
                        
                        # Lecture et d√©codage de l'image
                        f_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)
                        im = cv2.imdecode(f_bytes, 1)
                        
                        # Pr√©traitement
                        im_proc = process_signal(im, bri, con, gam, sha)
                        
                        # Mesure du temps de traitement
                        t0 = time.perf_counter()
                        
                        # Inf√©rence
                        dets = run_inference_pytorch(model, im_proc, conf_thresh, nms_thresh)
                        
                        # Calcul du temps en ms
                        dt = (time.perf_counter() - t0) * 1000
                        
                        # ========== AJOUT DES R√âSULTATS ==========
                        if dets:
                            # Si des avions ont √©t√© d√©tect√©s
                            for d in dets:
                                x1, y1, x2, y2 = map(int, d['box'])
                                all_detections.append({
                                    "Image": file.name,
                                    "Classe": d['label'],
                                    "Pr√©cision": d['score'],
                                    "Temps de traitement (ms)": int(dt),
                                    "Coordonn√©es": f"[{x1}, {y1}, {x2}, {y2}]"
                                })
                        else:
                            # Si aucune d√©tection, ajoute une ligne "R.A.S" (Rien √Ä Signaler)
                            all_detections.append({
                                "Image": file.name,
                                "Classe": "R.A.S",
                                "Pr√©cision": 0.0,
                                "Temps (ms)": int(dt),
                                "Coordonn√©es": "-"
                            })
                        
                        # Mise √† jour de la barre de progression
                        progress_bar.progress((i + 1) / len(uploaded_files))
                    
                    # ========== AFFICHAGE DES R√âSULTATS BATCH ==========
                    if all_detections:
                        # Conversion en DataFrame
                        df_all = pd.DataFrame(all_detections)
                        
                        # Tri par pr√©cision d√©croissante et formatage
                        df_display = df_all.sort_values(by="Pr√©cision", ascending=False).copy()
                        df_display["Pr√©cision"] = df_display["Pr√©cision"].apply(lambda x: f"{x:.2%}")
                        
                        # Message de succ√®s
                        st.success(f"Scan termin√© : {len(all_detections)} objets trait√©s.")
                        
                        # Affichage du tableau complet
                        st.dataframe(df_display, use_container_width=True)
                        
                        st.markdown("---")
                        
                        # ========== GRAPHIQUE DE R√âPARTITION DES CLASSES ==========
                        st.subheader("üìä R√©partition des Classes")
                        
                        # Filtrage pour exclure "R.A.S"
                        df_chart = df_all[df_all['Classe'] != "R.A.S"]
                        
                        if not df_chart.empty:
                            # Graphique en barres comptant les occurrences de chaque classe
                            # value_counts() compte le nombre de fois que chaque classe appara√Æt
                            st.bar_chart(df_chart['Classe'].value_counts())
                        else:
                            st.info("Rien √† signaler.")
                    else:
                        st.warning("Aucune d√©tection.")
                else:
                    # Si le mod√®le n'est pas charg√©
                    st.error("Mod√®le non charg√©.")
        else:
            # Si une seule image a √©t√© upload√©e
            st.info("Chargez plusieurs images pour activer le Scan Global.")
else:
    # Si aucune image n'a √©t√© upload√©e
    st.info("En attente d'images satellite...")
