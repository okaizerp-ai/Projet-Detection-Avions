"""
detection.py - G√©n√©ration d'Images Annot√©es avec D√©tections Visuelles

Ce script effectue l'inf√©rence du mod√®le V2 sur les images d'√©valuation et g√©n√®re
des visualisations avec les bo√Ætes englobantes et labels dessin√©s directement sur les images.

Utilit√©:
- Permet de v√©rifier visuellement les performances du mod√®le
- Utile pour la pr√©sentation et le rapport (captures d'√©cran des d√©tections)
- Aide √† identifier les erreurs du mod√®le (faux positifs, faux n√©gatifs)

Les images annot√©es sont sauvegard√©es dans outputs/DETECTIONS_VISUELLES/
avec le pr√©fixe "visu_" ajout√© au nom original.
"""

import torch  # PyTorch pour charger le mod√®le et faire l'inf√©rence
import torchvision.transforms as T  # Transformations d'images
from PIL import Image, ImageDraw, ImageFont  # Biblioth√®que PIL pour dessiner sur les images
import os  # Manipulation des chemins
import config  # Configuration centralis√©e (chemins, device, classes)
from model import get_model_instance_segmentation  # Architecture Faster R-CNN
from tqdm import tqdm  # Barre de progression pour suivre l'avancement

# ========== CONFIGURATION DES CHEMINS ==========
# Chemin vers le mod√®le V2 entra√Æn√© (dans le dossier models/)
MODEL_PATH = os.path.join(config.MODELS_DIR, 'faster_rcnn_avions_V2.pth')

# Dossier de sortie pour les images annot√©es (dans outputs/)
OUTPUT_DIR = os.path.join(config.OUTPUTS_DIR, 'DETECTIONS_VISUELLES')

# Cr√©ation du dossier de sortie s'il n'existe pas
# exist_ok=True √©vite une erreur si le dossier existe d√©j√†
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ========== 1. CHARGEMENT DU MOD√àLE V2 ==========
# Cr√©ation de l'architecture Faster R-CNN avec 21 classes
model = get_model_instance_segmentation(config.NUM_CLASSES)

# Chargement des poids du mod√®le V2 depuis le fichier .pth
# map_location=config.DEVICE assure la compatibilit√© GPU/CPU
model.load_state_dict(torch.load(MODEL_PATH, map_location=config.DEVICE))

# D√©placement du mod√®le sur GPU/CPU et activation du mode √©valuation
model.to(config.DEVICE)
model.eval()  # Mode eval: d√©sactive dropout, fige batch norm (crucial pour inf√©rence)

# ========== 2. LISTE DES IMAGES √Ä TRAITER ==========
# R√©cup√©ration du dossier contenant les images d'√©valuation du professeur
img_dir = config.EVAL_IMG_DIR

# Liste de tous les fichiers image du dossier
# List comprehension avec filtre sur les extensions d'images
# .lower() g√®re les extensions en majuscules (.JPG, .JPEG, .PNG)
# .endswith(tuple) v√©rifie si le nom se termine par une des extensions
all_images = [f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

# ========== 3. CHARGEMENT DE LA POLICE DE CARACT√àRES ==========
# Tentative de charger une police TrueType syst√®me (Linux)
try:
    # ImageFont.truetype() charge une police avec taille sp√©cifi√©e (ici 20 points)
    # Chemin typique sur Ubuntu/Debian
    font = ImageFont.truetype("/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf", 20)
except:
    # Si la police n'existe pas (Windows, Mac, autre Linux), utilise la police par d√©faut
    # La police par d√©faut est basique mais fonctionne partout
    font = ImageFont.load_default()

# Message d'information sur le d√©but du traitement
print(f"üé® G√©n√©ration des visuels dans : {OUTPUT_DIR}")

# ========== 4. BOUCLE DE D√âTECTION ET ANNOTATION ==========
# torch.no_grad() d√©sactive le calcul des gradients (√©conomise m√©moire et acc√©l√®re)
with torch.no_grad():
    
    # It√©ration sur toutes les images avec barre de progression
    for img_name in tqdm(all_images):
        
        # ========== CHARGEMENT DE L'IMAGE ==========
        # Construction du chemin complet vers l'image
        img_path = os.path.join(img_dir, img_name)
        
        # Ouverture de l'image avec PIL et conversion en RGB
        # .convert("RGB") force 3 canaux m√™me si l'image est en niveaux de gris
        img = Image.open(img_path).convert("RGB")
        
        # ========== PR√âPARATION DE L'IMAGE POUR LE MOD√àLE ==========
        # ToTensor() convertit PIL (H,W,C) [0-255] ‚Üí Tensor (C,H,W) [0-1]
        # .unsqueeze(0) ajoute la dimension batch: (C,H,W) ‚Üí (1,C,H,W)
        # .to(DEVICE) d√©place le tensor sur GPU/CPU
        img_tensor = T.Compose([T.ToTensor()])(img).unsqueeze(0).to(config.DEVICE)
        
        # ========== INF√âRENCE ==========
        # Le mod√®le retourne une liste de 1 dict (car batch_size=1):
        # [{'boxes': tensor, 'labels': tensor, 'scores': tensor}]
        prediction = model(img_tensor)
        
        # ========== CR√âATION DE L'OBJET DE DESSIN ==========
        # ImageDraw.Draw() cr√©e un contexte de dessin li√© √† l'image PIL
        # Permet de dessiner des rectangles, du texte, etc. directement sur l'image
        draw = ImageDraw.Draw(img)
        
        # ========== EXTRACTION DES R√âSULTATS ==========
        # D√©placement des tensors du GPU vers CPU et conversion en NumPy
        # prediction[0] car c'est une liste d'un seul √©l√©ment (batch_size=1)
        boxes = prediction[0]['boxes'].cpu().numpy()    # Array shape (N, 4)
        scores = prediction[0]['scores'].cpu().numpy()  # Array shape (N,)
        labels = prediction[0]['labels'].cpu().numpy()  # Array shape (N,)

        # ========== DESSIN DES D√âTECTIONS ==========
        # Boucle sur toutes les d√©tections (N objets d√©tect√©s)
        for i in range(len(boxes)):
            
            # ========== FILTRAGE PAR SEUIL DE CONFIANCE ==========
            # Garde seulement les d√©tections avec score > 50%
            # √âlimine les faux positifs (d√©tections incertaines)
            if scores[i] > 0.5:
                
                # Extraction des coordonn√©es de la bo√Æte (array NumPy [xmin, ymin, xmax, ymax])
                box = boxes[i]
                
                # ========== CONSTRUCTION DU LABEL TEXTE ==========
                # Convertit l'index (ex: 5) en label (ex: "A5")
                # Ajoute le score en pourcentage (ex: "(98%)")
                # int(scores[i]*100) convertit 0.987 ‚Üí 98
                label_txt = f"{config.CLASSES[labels[i]]} ({int(scores[i]*100)}%)"
                
                # ========== DESSIN DE LA BO√éTE ENGLOBANTE ==========
                # draw.rectangle() dessine un rectangle
                # Coordonn√©es: [(coin_sup√©rieur_gauche), (coin_inf√©rieur_droit)]
                # outline="lime" : Couleur du contour (vert fluo)
                # width=4 : √âpaisseur du trait en pixels
                draw.rectangle([(box[0], box[1]), (box[2], box[3])], outline="lime", width=4)
                
                # ========== DESSIN DU FOND DU LABEL ==========
                # Rectangle de fond pour rendre le texte lisible
                # Position: juste au-dessus de la bo√Æte principale
                # [(xmin, ymin-25), (xmin+130, ymin)] : rectangle de 130x25 pixels
                # fill="lime" : Couleur de remplissage (vert fluo)
                draw.rectangle([(box[0], box[1] - 25), (box[0] + 130, box[1])], fill="lime")
                
                # ========== DESSIN DU TEXTE ==========
                # draw.text() dessine du texte
                # Position: (xmin+5, ymin-22) = 5 pixels √† droite, 22 pixels au-dessus
                # L√©g√®rement d√©cal√© pour ne pas toucher les bords du rectangle vert
                # fill="black" : Couleur du texte (noir sur fond vert = bon contraste)
                # font=font : Utilise la police charg√©e pr√©c√©demment
                draw.text((box[0] + 5, box[1] - 22), label_txt, fill="black", font=font)

        # ========== SAUVEGARDE DE L'IMAGE ANNOT√âE ==========
        # .save() sauvegarde l'image PIL modifi√©e
        # Nom de sortie: "visu_" + nom original (ex: "visu_image_45.jpg")
        # Sauvegard√©e dans le dossier OUTPUT_DIR
        img.save(os.path.join(OUTPUT_DIR, f"visu_{img_name}"))

# Message de confirmation √† la fin du traitement
print(f"\n‚úÖ Termin√© !")
