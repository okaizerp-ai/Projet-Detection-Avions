"""
generate_json.py - G√©n√©ration du JSON d'√©valuation

Ce script effectue l'inf√©rence (pr√©diction) du mod√®le V2 sur les images d'√©valuation
fournies par le professeur et exporte les r√©sultats au format JSON.

Le JSON g√©n√©r√© contient pour chaque image:
- La classe pr√©dite (A1 √† A20)
- Le score de confiance (0 √† 1)
- Les coordonn√©es de la bounding box (xmin, ymin, xmax, ymax)

Ce fichier sera utilis√© par le professeur pour √©valuer automatiquement le mod√®le.

Format du JSON de sortie:
{
  "image1.jpg": [
    {
      "class": "A5",
      "score": 0.98,
      "coordinates": {"xmin": 100, "ymin": 200, "xmax": 300, "ymax": 400}
    },
    ...
  ],
  "image2.jpg": [...]
}
"""

import torch
import torchvision.transforms as T  # Transformations d'images
from PIL import Image  # Biblioth√®que de manipulation d'images
import os
import json  # Biblioth√®que pour lire/√©crire des fichiers JSON
import config  # Configuration centralis√©e (chemins, device, classes)
from model import get_model_instance_segmentation  # Architecture Faster R-CNN
from tqdm import tqdm  # Barre de progression pour suivi visuel

def run_evaluation():
    """
    Fonction principale qui orchestre l'√©valuation compl√®te:
    1. Charge le mod√®le V2 entra√Æn√©
    2. Lit toutes les images d'√©valuation
    3. Effectue l'inf√©rence (pr√©diction) sur chaque image
    4. Exporte les r√©sultats au format JSON
    """
    
    print(f"üöÄ Inf√©rence universelle sur : {config.DEVICE}")
    
    # ========== 1. CHARGEMENT DU MOD√àLE V2 ==========
    # Cr√©ation de l'architecture (21 classes)
    model = get_model_instance_segmentation(config.NUM_CLASSES)
    
    # Construction du chemin vers le mod√®le V2 sauvegard√©
    model_path = os.path.join(config.MODELS_DIR, 'faster_rcnn_avions_V2.pth')
    
    # V√©rification de l'existence du fichier
    if not os.path.exists(model_path):
        print(f"‚ùå Mod√®le introuvable dans : {model_path}")
        return  # Sort de la fonction si le mod√®le n'existe pas
    
    # Chargement des poids V2 dans le mod√®le
    # map_location=DEVICE g√®re la compatibilit√© GPU/CPU
    model.load_state_dict(torch.load(model_path, map_location=config.DEVICE))
    
    # D√©placement du mod√®le sur GPU/CPU et activation du mode √©valuation
    model.to(config.DEVICE)
    model.eval()  # Mode eval: d√©sactive dropout, fige batch norm (crucial pour inf√©rence)

    # ========== 2. LISTE DES IMAGES D'√âVALUATION ==========
    # R√©cup√©ration du dossier d'√©valuation depuis config
    eval_dir = config.EVAL_IMG_DIR
    
    # V√©rification de l'existence du dossier
    if not os.path.exists(eval_dir):
        print(f"‚ùå Dossier images introuvable : {eval_dir}")
        return  # Sort si le dossier n'existe pas
    
    # Liste de tous les fichiers image du dossier
    # List comprehension avec filtre sur les extensions image
    # .lower() pour g√©rer .JPG, .JPEG, .PNG (majuscules)
    all_images = [f for f in os.listdir(eval_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    
    # Dictionnaire qui contiendra tous les r√©sultats
    # Structure: {nom_image: [liste_d√©tections]}
    results = {}

    print(f"üîé Analyse de {len(all_images)} images pour le JSON...")

    # ========== 3. BOUCLE DE D√âTECTION ==========
    # torch.no_grad() d√©sactive le calcul des gradients
    # √âconomise m√©moire et acc√©l√®re les calculs (pas de backprop en inf√©rence)
    with torch.no_grad():
        
        # It√©ration sur toutes les images avec barre de progression
        for img_name in tqdm(all_images):
            
            # Construction du chemin complet vers l'image
            img_path = os.path.join(eval_dir, img_name)
            
            # Ouverture de l'image avec PIL et conversion en RGB
            # .convert("RGB") force 3 canaux m√™me si l'image est en niveaux de gris
            img = Image.open(img_path).convert("RGB")
            
            # Pr√©paration de l'image pour le mod√®le:
            # 1. T.ToTensor(): PIL (H,W,C) [0-255] ‚Üí Tensor (C,H,W) [0-1]
            # 2. .unsqueeze(0): Ajoute dimension batch (C,H,W) ‚Üí (1,C,H,W)
            #    Le mod√®le attend toujours un batch, m√™me d'une seule image
            # 3. .to(DEVICE): D√©place le tensor sur GPU/CPU
            img_t = T.Compose([T.ToTensor()])(img).unsqueeze(0).to(config.DEVICE)
            
            # Inf√©rence: le mod√®le retourne les pr√©dictions
            # prediction est une liste de 1 dict (car batch_size=1):
            # [{
            #     'boxes': tensor([[x1,y1,x2,y2], ...]),   # Coordonn√©es des bo√Ætes
            #     'labels': tensor([5, 12, 3]),             # Classes pr√©dites
            #     'scores': tensor([0.98, 0.87, 0.65])      # Confiances
            # }]
            prediction = model(img_t)
            
            # Liste qui contiendra les d√©tections de cette image
            img_preds = []
            
            # Extraction des tensors de pr√©diction et conversion en NumPy
            # .cpu() d√©place les tensors du GPU vers le CPU (PIL ne comprend pas CUDA)
            # .numpy() convertit les tensors PyTorch en arrays NumPy (format plus standard)
            boxes = prediction[0]['boxes'].cpu().numpy()    # Array shape (N, 4)
            labels = prediction[0]['labels'].cpu().numpy()  # Array shape (N,)
            scores = prediction[0]['scores'].cpu().numpy()  # Array shape (N,)
            
            # Boucle sur toutes les d√©tections de cette image
            for i in range(len(boxes)):
                
                # Filtrage par seuil de confiance: garde seulement les d√©tections > 50%
                # √âlimine les faux positifs (d√©tections incertaines)
                if scores[i] > 0.5:
                    
                    # Extraction de la bo√Æte actuelle (array NumPy [xmin, ymin, xmax, ymax])
                    box = boxes[i]
                    
                    # Construction du dictionnaire de d√©tection au format JSON
                    img_preds.append({
                        # Conversion de l'index (ex: 5) en label (ex: "A5")
                        "class": config.CLASSES[labels[i]],
                        
                        # Conversion du tensor en float Python pour s√©rialisation JSON
                        "score": float(scores[i]),
                        
                        # Dictionnaire des coordonn√©es (conversion en int = pixels entiers)
                        "coordinates": {
                            "xmin": int(box[0]),  # Coin sup√©rieur gauche X
                            "ymin": int(box[1]),  # Coin sup√©rieur gauche Y
                            "xmax": int(box[2]),  # Coin inf√©rieur droit X
                            "ymax": int(box[3])   # Coin inf√©rieur droit Y
                        }
                    })
            
            # Association du nom d'image √† sa liste de d√©tections dans le dict global
            results[img_name] = img_preds

    # ========== 4. SAUVEGARDE DU JSON ==========
    # Construction du chemin de sortie dans le dossier outputs/
    output_json = os.path.join(config.OUTPUTS_DIR, 'predictions_officielles.json')
    
    # Ouverture du fichier en mode √©criture ('w' = write)
    # 'with' assure la fermeture automatique du fichier m√™me en cas d'erreur
    with open(output_json, 'w') as f:
        # S√©rialisation du dictionnaire Python en JSON
        # indent=2 formate le JSON avec indentation (lisible par humain)
        # Sans indent, tout serait sur une seule ligne
        json.dump(results, f, indent=2)

    print(f"\n‚úÖ JSON g√©n√©r√© avec succ√®s dans : {output_json}")

# ========== POINT D'ENTR√âE DU SCRIPT ==========
# Ex√©cute run_evaluation() seulement si le script est lanc√© directement
# (pas si import√© avec 'import generate_json')
if __name__ == "__main__":
    run_evaluation()
