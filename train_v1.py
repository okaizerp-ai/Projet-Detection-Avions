"""
train_v1.py - Entra√Ænement Baseline (Version 1)

Ce script effectue le premier entra√Ænement du mod√®le Faster R-CNN.
Il part des poids pr√©-entra√Æn√©s sur COCO et les adapte √† notre dataset d'avions.
C'est la version "Baseline" qui sert de r√©f√©rence pour mesurer les am√©liorations.

Strat√©gie:
- Split 80/20 avec r√©serve de 50 images pour test final
- Learning Rate standard (0.005) pour un premier entra√Ænement
- 10 √©poques pour permettre au mod√®le de bien converger
"""

import torch
import os
import config  # Import de la configuration centralis√©e (chemins, hyperparam√®tres)
from model import get_model_instance_segmentation  # Architecture Faster R-CNN
from dataset import PlaneDataset  # Classe de chargement des donn√©es
import torchvision.transforms as T  # Transformations d'images
from torch.utils.data import DataLoader, Subset  # Outils de chargement par batch

def get_transform():
    """
    D√©finit les transformations √† appliquer aux images.
    
    Returns:
        T.Compose: Pipeline de transformations
        - ToTensor(): Convertit l'image PIL (0-255) en tensor PyTorch (0-1)
          et change le format de (H, W, C) √† (C, H, W)
    """
    return T.Compose([T.ToTensor()])

# --- CONFIGURATION VIA CONFIG.PY ---
# R√©cup√©ration du device (GPU si disponible, sinon CPU)
DEVICE = config.DEVICE

# ========== 1. PR√âPARATION DES DONN√âES ==========
# Chargement du dataset complet depuis le dossier data/
# PlaneDataset lit les images et annotations XML (format PASCAL VOC)
dataset = PlaneDataset(config.DATA_DIR, transforms=get_transform())

# Cr√©ation d'un split train/test al√©atoire
# torch.randperm() g√©n√®re une permutation al√©atoire des indices [0, 1, 2, ..., N-1]
indices = torch.randperm(len(dataset)).tolist()

# On garde toutes les images SAUF les 50 derni√®res (apr√®s m√©lange)
# Ces 50 images serviront de test final pour √©valuer le mod√®le V1
# Exemple: Si 1331 images ‚Üí dataset_train contient 1281 images
dataset_train = Subset(dataset, indices[:-50])

# DataLoader: charge les donn√©es par batchs (groupes d'images)
data_loader = DataLoader(
    dataset_train,  # Sous-dataset d'entra√Ænement
    batch_size=4,   # Traite 4 images √† la fois (limit√© par m√©moire GPU)
    shuffle=True,   # M√©lange les images √† chaque √©poque (√©vite apprentissage de l'ordre)
    collate_fn=lambda x: tuple(zip(*x))  # Fonction pour assembler les batchs
    # collate_fn n√©cessaire car les images ont des tailles diff√©rentes
    # Transforme [(img1, target1), (img2, target2)] en ([img1, img2], [target1, target2])
)

# ========== 2. CR√âATION DU MOD√àLE ==========
# Initialisation du mod√®le Faster R-CNN avec 21 classes (20 avions + 1 background)
model = get_model_instance_segmentation(config.NUM_CLASSES)

# D√©placement du mod√®le sur le GPU (ou CPU si GPU indisponible)
# Cette √©tape est CRUCIALE pour utiliser le GPU
model.to(DEVICE)

# ========== 3. CONFIGURATION DE L'OPTIMISEUR ==========
# R√©cup√©ration des param√®tres entra√Ænables du mod√®le
# requires_grad=True signifie que le param√®tre sera mis √† jour pendant l'entra√Ænement
params = [p for p in model.parameters() if p.requires_grad]

# Optimiseur SGD (Stochastic Gradient Descent)
# Algorithme qui ajuste les poids du mod√®le pour minimiser la loss
optimizer = torch.optim.SGD(
    params,              # Param√®tres √† optimiser
    lr=0.005,            # Learning Rate: taille du pas de descente (standard pour V1)
    momentum=0.9,        # Momentum: acc√©l√®re la convergence en m√©morisant la direction
    weight_decay=0.0005  # R√©gularisation L2: p√©nalise les poids trop √©lev√©s (√©vite overfitting)
)

# ========== 4. BOUCLE D'ENTRA√éNEMENT ==========
num_epochs = 10  # Nombre de passages complets sur le dataset
print(f"üöÄ D√©but de l'entra√Ænement Baseline (V1) sur : {DEVICE}")

# Boucle principale: r√©p√®te l'entra√Ænement sur toutes les donn√©es 10 fois
for epoch in range(num_epochs):
    
    # Mode entra√Ænement: active dropout, batch normalization, etc.
    model.train()
    
    # Compteur d'it√©rations pour affichage
    i = 0
    
    # It√©ration sur les batchs de donn√©es
    for images, targets in data_loader:
        # D√©placement des images sur le GPU/CPU
        # List comprehension qui applique .to(DEVICE) √† chaque image
        images = list(image.to(DEVICE) for image in images)
        
        # D√©placement des annotations (targets) sur le GPU/CPU
        # Dict comprehension imbriqu√©e: pour chaque target, d√©place toutes ses valeurs
        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]

        # Forward pass: le mod√®le calcule la loss automatiquement en mode train
        # Faster R-CNN calcule 4 losses (RPN classification, RPN regression, ROI classification, ROI regression)
        loss_dict = model(images, targets)
        
        # Somme des 4 losses pour obtenir la loss totale
        losses = sum(loss for loss in loss_dict.values())

        # Backward pass: calcul des gradients
        # √âtape 1: R√©initialiser les gradients √† z√©ro (PyTorch les accumule par d√©faut)
        optimizer.zero_grad()
        
        # √âtape 2: R√©tropropagation - calcule les gradients de la loss par rapport √† chaque poids
        losses.backward()
        
        # √âtape 3: Mise √† jour des poids selon la formule SGD avec momentum
        optimizer.step()

        # Affichage de la loss tous les 10 batchs pour suivre la progression
        if i % 10 == 0:
            # .item() convertit le tensor en float Python pour l'affichage
            print(f"√âpoque {epoch+1}, It√©ration {i}, Loss: {losses.item():.4f}")
        i += 1

# ========== 5. SAUVEGARDE DU MOD√àLE ==========
# Construction du chemin de sauvegarde dans le dossier models/
save_path = os.path.join(config.MODELS_DIR, 'faster_rcnn_avions.pth')

# Sauvegarde des poids du mod√®le (state_dict = dictionnaire de tous les param√®tres)
# Seuls les poids sont sauvegard√©s, pas l'architecture ni l'optimiseur
torch.save(model.state_dict(), save_path)

print(f"‚úÖ Entra√Ænement V1 termin√© ! Mod√®le sauvegard√© dans : {save_path}")
