"""
train_v2.py - Fine-Tuning (Version 2)

Ce script effectue le fine-tuning du mod√®le V1 pour am√©liorer ses performances.
Il charge les poids de la V1 et continue l'entra√Ænement avec:
- Un learning rate plus faible (0.0005 vs 0.005) pour ajustements pr√©cis
- Tout le dataset (pas de split) pour maximiser les donn√©es d'apprentissage
- Data augmentation cibl√©e sur les classes faibles (dans dataset.py)
- Barre de progression (tqdm) pour suivi visuel

Objectif: Gagner 5 points de F1-Score par rapport √† V1 (69% ‚Üí 74%)
"""

import torch
import os
import config  # Configuration centralis√©e (chemins, device, hyperparam√®tres)
from model import get_model_instance_segmentation  # Architecture Faster R-CNN
from dataset import PlaneDataset  # Dataset avec data augmentation int√©gr√©e
import torchvision.transforms as T  # Transformations d'images
from tqdm import tqdm  # Biblioth√®que pour barres de progression visuelles

# --- CONFIGURATION VIA CONFIG.PY ---
# R√©cup√©ration automatique du device (cuda ou cpu)
DEVICE = config.DEVICE

# ========== 1. CHARGEMENT DU MOD√àLE V1 (TRANSFER LEARNING INTERNE) ==========
# Cr√©ation de l'architecture avec 21 classes (identique √† V1)
model = get_model_instance_segmentation(config.NUM_CLASSES)

# Construction du chemin vers le mod√®le V1 sauvegard√©
checkpoint_path = os.path.join(config.MODELS_DIR, 'faster_rcnn_avions.pth')

# V√©rification de l'existence du fichier de poids V1
if os.path.exists(checkpoint_path):
    print(f"üíé Chargement du mod√®le existant (V1) depuis : {checkpoint_path}")
    
    # Chargement des poids V1 dans le mod√®le
    # torch.load() d√©s√©rialise le fichier .pth en dictionnaire de tensors
    # map_location=DEVICE assure la compatibilit√© GPU/CPU (charge sur le bon device)
    model.load_state_dict(torch.load(checkpoint_path, map_location=DEVICE))
else:
    # Si V1 n'existe pas, on part des poids COCO pr√©-entra√Æn√©s
    print(f"‚ö†Ô∏è Attention : {checkpoint_path} non trouv√©. Le Fine-Tuning partira de z√©ro.")

# D√©placement du mod√®le sur GPU/CPU
model.to(DEVICE)

# ========== 2. OPTIMISEUR AVEC LEARNING RATE FAIBLE ==========
# R√©cup√©ration des param√®tres entra√Ænables
params = [p for p in model.parameters() if p.requires_grad]

# Optimiseur SGD avec LR divis√© par 10 par rapport √† V1
optimizer = torch.optim.SGD(
    params,
    lr=0.0005,           # Learning Rate FAIBLE (0.0005 vs 0.005 en V1)
                         # Raison: Fine-tuning n√©cessite des ajustements d√©licats
                         # Un LR trop √©lev√© "casserait" les connaissances de V1
    momentum=0.9,        # M√™me momentum qu'en V1 (valeur standard)
    weight_decay=0.0005  # M√™me r√©gularisation L2 qu'en V1
)

# ========== 3. DATALOADER AVEC TOUT LE DATASET ==========
# Chargement du dataset COMPLET (toutes les ~1331 images)
# PlaneDataset applique automatiquement la data augmentation cibl√©e:
# - 80% de flip pour classes faibles (A1, A12, A15, A18, A20)
# - 50% de flip pour les autres classes
dataset = PlaneDataset(config.DATA_DIR, transforms=T.Compose([T.ToTensor()]))

# DataLoader pour charger les donn√©es par batchs
data_loader = torch.utils.data.DataLoader(
    dataset,             # Dataset complet (pas de Subset comme en V1)
    batch_size=4,        # M√™me batch size qu'en V1
    shuffle=True,        # M√©lange √† chaque √©poque
    num_workers=0,       # Pas de processus parall√®les (plus stable sur Windows/Mac)
                         # num_workers=4 serait plus rapide mais peut causer des bugs
    collate_fn=lambda x: tuple(zip(*x))  # Assemblage des batchs (voir train_v1.py)
)

# ========== 4. BOUCLE D'ENTRA√éNEMENT AVEC TQDM ==========
num_epochs = 7  # Moins d'√©poques qu'en V1 (7 vs 10) car on part de V1 d√©j√† entra√Æn√©
print(f"üöÄ D√©but du Fine-Tuning V2 sur : {DEVICE}")

# Boucle principale sur les √©poques
for epoch in range(num_epochs):
    
    # Mode entra√Ænement (active dropout, batch norm, etc.)
    model.train()
    
    # Cr√©ation de la barre de progression pour l'√©poque actuelle
    # tqdm() enveloppe le DataLoader et affiche [‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 67% | loss=0.234
    prog_bar = tqdm(data_loader, desc=f"√âpoque {epoch+1}/{num_epochs}")
    
    # Accumulation de la loss pour calcul de moyenne en fin d'√©poque
    epoch_loss = 0
    
    # It√©ration sur les batchs avec barre de progression
    for images, targets in prog_bar:
        # D√©placement des donn√©es sur GPU/CPU (identique √† V1)
        images = list(image.to(DEVICE) for image in images)
        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]
        
        # Forward pass: calcul de la loss
        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())
        
        # Backward pass: calcul des gradients et mise √† jour des poids
        optimizer.zero_grad()  # Reset gradients
        losses.backward()       # Calcul gradients
        optimizer.step()        # Mise √† jour poids
        
        # Accumulation de la loss pour statistiques
        epoch_loss += losses.item()
        
        # Mise √† jour de la barre de progression avec la loss actuelle
        # Affiche la loss √† droite de la barre: [‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] | loss=0.234
        prog_bar.set_postfix(loss=losses.item())
    
    # Calcul de la loss moyenne de l'√©poque
    # len(data_loader) = nombre de batchs dans l'√©poque
    avg_loss = epoch_loss / len(data_loader)
    
    # Affichage de la loss moyenne (indicateur de progression)
    # Cette valeur doit diminuer au fil des √©poques
    print(f"‚úÖ √âpoque {epoch+1} termin√©e. Perte moyenne : {avg_loss:.4f}")

# ========== 5. SAUVEGARDE DU MOD√àLE V2 ==========
# Sauvegarde sous un nom diff√©rent pour garder V1 intact
save_path = os.path.join(config.MODELS_DIR, 'faster_rcnn_avions_V2.pth')

# Sauvegarde des poids uniquement (pas l'architecture ni l'optimiseur)
torch.save(model.state_dict(), save_path)

print(f"‚ú® Bravo ! Le mod√®le V2 est sauvegard√© ici : {save_path}")
